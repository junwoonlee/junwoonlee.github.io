<!DOCTYPE html>
<html>


  <meta charset="utf-8">
  <title>LatentAM</title>
  <!-- Google tag (gtag.js) -->
<!-- <script async src="https://www.googletagmanager.com/gtag/js?id=G-xxxxxxxxx"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-xxxxxxxxx');
</script> -->

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
  <link rel="icon" type="image/svg+xml" href="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0%200%2064%2064'%3E%3Ctext x='50%25' y='50%25' dominant-baseline='middle' text-anchor='middle' font-size='52'%3EðŸ“˜%3C/text%3E%3C/svg%3E" />
  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>



<style>
  @media only screen and (max-width: 850px) {
    .column.is-three-fifths {
      width: 85%; /* Adjust the width as per your requirement */
      margin: auto; /* Center the div */
    }
  }
  .video-container {
    text-align: center;
    margin: 20px 0;
  }

  /* Extra vertical spacing for the top hero section */
  #latam-hero .hero-body { padding-top: 3.5rem; padding-bottom: 2.5rem; }
  #latam-hero .publication-title { margin-bottom: 1.25rem; line-height: 1.2; }
  #latam-hero .is-size-5 { margin-top: .5rem; }
  #latam-hero .publication-authors { margin-top: .5rem; margin-bottom: .75rem; }
</style>

<section class="hero" id="latam-hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-2 publication-title">
            <small>LatentAM: Real-Time, Large-Scale Latent Gaussian Attention Mapping
              via Online Dictionary Learning</small>
          </h1>
          <div class="is-size-5 ">
            <span class="author-block">
              <a href="https://junwoonlee.github.io/" target="_blank">Junwoon Lee</a>&nbsp;&nbsp;&nbsp;
            </span>
            <span class="author-block">
              <a href="https://www.tianyulun.com/" target="_blank">Yulun Tian</a>&nbsp;&nbsp;&nbsp;
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">Robotics Department, University of Michigan</span>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="is-size-4 author-block">Under Review</span>
          </div>

          <br>
          <div class="publication-links">
            <span class="link-block">
              <a href="#" class="external-link button is-normal is-rounded is-dark" aria-disabled="true">
                <span class="icon"><i class="fas fa-file-pdf"></i></span>
                <span>Paper (Soon)</span>
              </a>
            </span>
            <span class="link-block">
              <a href="#" class="external-link button is-normal is-rounded is-dark" aria-disabled="true">
                <span class="icon"><i class="fab fa-github"></i></span>
                <span>Code (Soon)</span>
              </a>
            </span>
            <span class="link-block">
              <a href="https://drive.google.com/file/d/15LevbsW4eOo3NYz8b6jDZdL7rFZi0lKn/view?usp=sharing" target="_blank" rel="noopener" class="external-link button is-normal is-rounded is-dark">
                <span class="icon"><i class="fas fa-file-video"></i></span>
                <span>Video</span>
              </a>
            </span>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero is-small">
  <div class="hero-body">
    <div class="columns is-centered has-text-centered">
      <div class="column is-three-fifths">
        <div class="container">

          <div class="content has-text-justified">
            <div style="position:relative;padding-top:56.25%;">
              <!-- Replace VIDEO_ID with your YouTube video ID -->
              <iframe src="https://drive.google.com/file/d/15LevbsW4eOo3NYz8b6jDZdL7rFZi0lKn/preview" allowfullscreen style="position:absolute;top:0;left:0;width:100%;height:100%;"></iframe>
            </div>
            <div class="notification is-warning is-light is-size-4 has-text-centered" style="margin-top: 1rem;">
              <strong>Under construction.</strong> More demos will be added soon.
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero is-small">
  <div class="hero-body">
    <div class="columns is-centered has-text-centered">
      <div class="column is-three-fifths">
        <div class="container">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              We present <strong>LatentAM</strong>, an online 3D Gaussian Splatting (3DGS) mapping framework
              that builds scalable latent feature maps from streaming RGB-D observations for open-vocabulary
              robotic perception. Instead of distilling high-dimensional Vision-Language Model (VLM) embeddings
              using model-specific decoders, LatentAM proposes an online dictionary learning
              approach that is both model-agnostic and pretraining-free, enabling plug-and-play integration
              with different VLMs at test time. 
              Specifically, our approach associates each Gaussian primitive with a compact query vector that can
              be converted into approximate VLM embeddings using an attention mechanism with a learnable dictionary.
              The dictionary is initialized efficiently from streaming observations and optimized online to adapt
              to evolving scene semantics under trust-region regularization. 
              To scale to long trajectories and large environments, we further propose an efficient map management
              strategy based on voxel hashing, where optimization is restricted to an active local map on the GPU,
              while the global map is stored and indexed on the CPU to maintain bounded GPU memory usage. 
              Experiments on public benchmarks and a large-scale custom dataset demonstrate that 
              LatentAM attains significantly better feature reconstruction fidelity compared to 
              state-of-the-art methods, while achieving near-real-time speed (12-35 FPS) on the evaluated datasets.
            </p>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@inproceedings{lee2026latentam,
  title     = {LatentAM: Real-Time, Large-Scale Latent Gaussian Attention Mapping
    via Online Dictionary Learning},
  author    = {Lee, Junwoon and Tian, Yulun},
  booktitle = {To appear},
  year      = {2026}
}</code></pre>
  </div>
</section>
</html>

<style>
	.collapsible {
		background-color: #eee;
		color: #444;
		cursor: pointer;
		padding: 18px;
		width: 100%;
		border: none;
		text-align: left;
		outline: none;
		font-size: 15px;
	}
	.active,
	.collapsible:hover {
		background-color: #ccc;
	}
	.collapsible:after {
		content: "\02795"; /* + */
		font-size: 13px;
		float: right;
		margin-left: 5px;
	}
	.active:after {
		content: "\2796"; /* - */
	}
	#toc {
		padding: 0 18px;
		display: none;
		background-color: #f1f1f1;
	}
</style>
